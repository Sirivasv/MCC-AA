{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProyectoFinal_TrainingEvaluation_Saul_Rivas.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "jwXad0vKVy7z"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC-EDxEfRpj7",
        "colab_type": "text"
      },
      "source": [
        "# Training and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PKGgBCgV4U5",
        "colab_type": "text"
      },
      "source": [
        "In this notebook the training and evaluation of a naive bayesian model is done. It will be evaluated in a 10 repetition 5-Fold cross validation set up. The result will be a median accuracy across all of the repetitions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwXad0vKVy7z",
        "colab_type": "text"
      },
      "source": [
        "## The Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRwKGA_DWWwb",
        "colab_type": "text"
      },
      "source": [
        "The model to be trained is a naive bayesian classifier. The features were extracted using the procedure explained in:\n",
        "https://colab.research.google.com/drive/1FFOlA5Q2O5TdxpVnBq7qKkHAbK6a0fvj?usp=sharing\n",
        "\n",
        "Each of the frequency energies are real numbers assumed to be normal distributed and the paired labels of family_pitch assumed from a categorical distribution.\n",
        "\n",
        "This is for the feature vectors $X$: $$\\mathcal{N}(X_i;\\mu;\\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}e^{\\frac{-(X_i - \\mu)^2}{2\\sigma^2}}$$\n",
        "\n",
        "And for the paired labels $Y$: $$Y \\leftarrow argmaxA_{y_k} P(Y = y_k)\\prod_{i}^{d}{P(X_i|Y = y_k)}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyvfOunqWakA",
        "colab_type": "text"
      },
      "source": [
        "## Implementation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRxdDM6HdT0a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "%matplotlib inline\n",
        "random.seed(2020)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZLVwx0ugzbe",
        "colab_type": "code",
        "outputId": "b21f5189-6815-44ed-90c5-94f64ff2c472",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "# We get the feature dataset\n",
        "!wget -O family_note_features.csv https://raw.githubusercontent.com/Sirivasv/MCC-AA/master/ProyectoFinal/family_note_features.csv"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-04 09:00:31--  https://raw.githubusercontent.com/Sirivasv/MCC-AA/master/ProyectoFinal/family_note_features.csv\r\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.48.133\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.48.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 43994342 (42M) [text/plain]\n",
            "Saving to: ‘family_note_features.csv’\n",
            "\n",
            "family_note_feature 100%[===================>]  41.96M  5.35MB/s    in 8.1s    \n",
            "\n",
            "2020-06-04 09:00:40 (5.16 MB/s) - ‘family_note_features.csv’ saved [43994342/43994342]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DG9GLlbXhFWT",
        "colab_type": "code",
        "outputId": "9f2bdfe1-d949-47c5-9f77-5e342c4b9a2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        }
      },
      "source": [
        "# We show the head of the dataset\n",
        "family_notes_df = pd.read_csv(\"family_note_features.csv\")\n",
        "family_notes_df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        segment_name   note_24   note_25   note_26   note_27  \\\n",
              "0  string_acoustic_011-026-127_seg_0  0.060915  0.078695  0.048240  0.102672   \n",
              "1  string_acoustic_011-026-127_seg_1  0.055939  0.078754  0.068669  0.108313   \n",
              "2  string_acoustic_011-026-127_seg_2  0.046108  0.077479  0.109768  0.124337   \n",
              "3  string_acoustic_011-026-127_seg_3  0.041050  0.077621  0.157035  0.150372   \n",
              "4  string_acoustic_011-026-127_seg_4  0.045203  0.084967  0.202651  0.182410   \n",
              "\n",
              "    note_28   note_29   note_30   note_31   note_32  ...   note_99  \\\n",
              "0  0.002660  0.067364  0.016569  0.055188  0.043170  ...  0.000001   \n",
              "1  0.035690  0.061008  0.031879  0.059526  0.042898  ...  0.000910   \n",
              "2  0.054667  0.049494  0.049995  0.061188  0.055727  ...  0.001135   \n",
              "3  0.053375  0.045698  0.056476  0.055910  0.063097  ...  0.003440   \n",
              "4  0.046832  0.054968  0.051309  0.043172  0.059405  ...  0.003629   \n",
              "\n",
              "       note_100      note_101      note_102      note_103      note_104  \\\n",
              "0  1.400782e-07  1.129644e-07  7.845241e-07  3.064818e-07  8.880471e-07   \n",
              "1  1.075201e-03  4.154219e-04  1.315951e-04  6.029340e-05  4.100908e-05   \n",
              "2  1.278791e-03  2.765147e-04  7.012750e-04  8.349395e-04  6.810263e-04   \n",
              "3  5.911199e-03  5.680938e-03  4.629928e-03  3.378918e-03  1.862395e-03   \n",
              "4  1.441651e-03  1.284077e-03  3.948394e-03  2.435748e-03  6.445605e-04   \n",
              "\n",
              "       note_105      note_106      note_107             NOTE_CLASS  \n",
              "0  3.291851e-07  7.803614e-07  5.115749e-07  family_string_note_26  \n",
              "1  1.625531e-04  2.255030e-04  1.986155e-04  family_string_note_26  \n",
              "2  6.534754e-04  4.423557e-04  9.610463e-04  family_string_note_26  \n",
              "3  1.057562e-03  9.777358e-04  2.081144e-03  family_string_note_26  \n",
              "4  5.838733e-04  1.244309e-03  2.766589e-03  family_string_note_26  \n",
              "\n",
              "[5 rows x 86 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>segment_name</th>\n",
              "      <th>note_24</th>\n",
              "      <th>note_25</th>\n",
              "      <th>note_26</th>\n",
              "      <th>note_27</th>\n",
              "      <th>note_28</th>\n",
              "      <th>note_29</th>\n",
              "      <th>note_30</th>\n",
              "      <th>note_31</th>\n",
              "      <th>note_32</th>\n",
              "      <th>...</th>\n",
              "      <th>note_99</th>\n",
              "      <th>note_100</th>\n",
              "      <th>note_101</th>\n",
              "      <th>note_102</th>\n",
              "      <th>note_103</th>\n",
              "      <th>note_104</th>\n",
              "      <th>note_105</th>\n",
              "      <th>note_106</th>\n",
              "      <th>note_107</th>\n",
              "      <th>NOTE_CLASS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>string_acoustic_011-026-127_seg_0</td>\n",
              "      <td>0.060915</td>\n",
              "      <td>0.078695</td>\n",
              "      <td>0.048240</td>\n",
              "      <td>0.102672</td>\n",
              "      <td>0.002660</td>\n",
              "      <td>0.067364</td>\n",
              "      <td>0.016569</td>\n",
              "      <td>0.055188</td>\n",
              "      <td>0.043170</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>1.400782e-07</td>\n",
              "      <td>1.129644e-07</td>\n",
              "      <td>7.845241e-07</td>\n",
              "      <td>3.064818e-07</td>\n",
              "      <td>8.880471e-07</td>\n",
              "      <td>3.291851e-07</td>\n",
              "      <td>7.803614e-07</td>\n",
              "      <td>5.115749e-07</td>\n",
              "      <td>family_string_note_26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>string_acoustic_011-026-127_seg_1</td>\n",
              "      <td>0.055939</td>\n",
              "      <td>0.078754</td>\n",
              "      <td>0.068669</td>\n",
              "      <td>0.108313</td>\n",
              "      <td>0.035690</td>\n",
              "      <td>0.061008</td>\n",
              "      <td>0.031879</td>\n",
              "      <td>0.059526</td>\n",
              "      <td>0.042898</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000910</td>\n",
              "      <td>1.075201e-03</td>\n",
              "      <td>4.154219e-04</td>\n",
              "      <td>1.315951e-04</td>\n",
              "      <td>6.029340e-05</td>\n",
              "      <td>4.100908e-05</td>\n",
              "      <td>1.625531e-04</td>\n",
              "      <td>2.255030e-04</td>\n",
              "      <td>1.986155e-04</td>\n",
              "      <td>family_string_note_26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>string_acoustic_011-026-127_seg_2</td>\n",
              "      <td>0.046108</td>\n",
              "      <td>0.077479</td>\n",
              "      <td>0.109768</td>\n",
              "      <td>0.124337</td>\n",
              "      <td>0.054667</td>\n",
              "      <td>0.049494</td>\n",
              "      <td>0.049995</td>\n",
              "      <td>0.061188</td>\n",
              "      <td>0.055727</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001135</td>\n",
              "      <td>1.278791e-03</td>\n",
              "      <td>2.765147e-04</td>\n",
              "      <td>7.012750e-04</td>\n",
              "      <td>8.349395e-04</td>\n",
              "      <td>6.810263e-04</td>\n",
              "      <td>6.534754e-04</td>\n",
              "      <td>4.423557e-04</td>\n",
              "      <td>9.610463e-04</td>\n",
              "      <td>family_string_note_26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>string_acoustic_011-026-127_seg_3</td>\n",
              "      <td>0.041050</td>\n",
              "      <td>0.077621</td>\n",
              "      <td>0.157035</td>\n",
              "      <td>0.150372</td>\n",
              "      <td>0.053375</td>\n",
              "      <td>0.045698</td>\n",
              "      <td>0.056476</td>\n",
              "      <td>0.055910</td>\n",
              "      <td>0.063097</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003440</td>\n",
              "      <td>5.911199e-03</td>\n",
              "      <td>5.680938e-03</td>\n",
              "      <td>4.629928e-03</td>\n",
              "      <td>3.378918e-03</td>\n",
              "      <td>1.862395e-03</td>\n",
              "      <td>1.057562e-03</td>\n",
              "      <td>9.777358e-04</td>\n",
              "      <td>2.081144e-03</td>\n",
              "      <td>family_string_note_26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>string_acoustic_011-026-127_seg_4</td>\n",
              "      <td>0.045203</td>\n",
              "      <td>0.084967</td>\n",
              "      <td>0.202651</td>\n",
              "      <td>0.182410</td>\n",
              "      <td>0.046832</td>\n",
              "      <td>0.054968</td>\n",
              "      <td>0.051309</td>\n",
              "      <td>0.043172</td>\n",
              "      <td>0.059405</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003629</td>\n",
              "      <td>1.441651e-03</td>\n",
              "      <td>1.284077e-03</td>\n",
              "      <td>3.948394e-03</td>\n",
              "      <td>2.435748e-03</td>\n",
              "      <td>6.445605e-04</td>\n",
              "      <td>5.838733e-04</td>\n",
              "      <td>1.244309e-03</td>\n",
              "      <td>2.766589e-03</td>\n",
              "      <td>family_string_note_26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 86 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGSOoVm-hX4I",
        "colab_type": "text"
      },
      "source": [
        "Each category has the same number of samples so in a categorical distribution for the naive bayes classifier the probability $P(Y=y)$ is the same for each of the $y\\in Y$ which is $\\sum{\\frac{Y=y}{N}}$.\n",
        "$$ \\frac{224}{24864} = 0.009009009009009009$$ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCmhtaYqif_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define hyperparameters and probality for all classes\n",
        "p_y_num = 224.0\n",
        "p_y_den = 24864.0\n",
        "\n",
        "k_cv = 7 # k-fold corss-validation\n",
        "cv_repetitions = 10 # Repetitions for the cross-validation\n",
        "family_names = [\"string\", \"guitar\", \"brass\"] # The instrument families to identify\n",
        "n_families = 3\n",
        "n_pitches = 37 # The number of pitches in the identifyible range for the classifier\n",
        "start_pitch = 24 # The starting pitch in MIDI notation (e.g. 24 for C1)\n",
        "feature_pitches = 84 # The Range of pitches as features\n",
        "n_frames = 16.0 # Frammes taken from each pitch for each instrument\n",
        "\n",
        "# We initialize the dictionaries to store the means and variances of each\n",
        "# category\n",
        "means_per_category = {}\n",
        "variances_per_category = {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WO8HDtEPlKj5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the instruments present for each family-pitch paired label\n",
        "samples_in_family_note = 0\n",
        "instrument_samples_per_category = {}\n",
        "for i in range(n_pitches):\n",
        "  note_i = i + start_pitch\n",
        "  for family_name in family_names:\n",
        "    category_name = \"family_\" + family_name + \"_note_\"+ str(note_i)\n",
        "    instrument_samples_per_category[category_name] = {}\n",
        "    samples_in_family_note = family_notes_df[family_notes_df[\"NOTE_CLASS\"] == category_name].copy()\n",
        "    for index, row in samples_in_family_note.iterrows():\n",
        "      segmented_instrument_name = row[\"segment_name\"].split(\"_\")\n",
        "      instrument_source_name = segmented_instrument_name[0] + \"_\" + segmented_instrument_name[1] + \"_\" + segmented_instrument_name[2]\n",
        "      if (not(instrument_source_name in instrument_samples_per_category[category_name])):\n",
        "        instrument_samples_per_category[category_name][instrument_source_name] = pd.DataFrame()\n",
        "      instrument_samples_per_category[category_name][instrument_source_name] = instrument_samples_per_category[category_name][instrument_source_name].append(row)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3muE3hJwPvk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We traverse the features names\n",
        "feature_names = []\n",
        "for feature_i in range(feature_pitches):\n",
        "  feature_name = \"note_\" + str(start_pitch + feature_i)\n",
        "  feature_names.append(feature_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAfEPbxJwbmx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the family_notes key list\n",
        "family_note_category_keys = np.array(list(instrument_samples_per_category.keys()))\n",
        "instrument_sources_per_category_keys = {}\n",
        "for family_note_category_key in family_note_category_keys:\n",
        "  instrument_sources_per_category_keys[family_note_category_key] = np.array(list(instrument_samples_per_category[family_note_category_key].keys()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPTMBAqWrctA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define Required functions \n",
        "def Gaussian_PDF(x, mean_y, variance_y):\n",
        "    # Input the arguments into a probability density function\n",
        "    p = 1/(np.sqrt(2*np.pi*variance_y)) * np.exp((-(x-mean_y)**2)/(2*variance_y))\n",
        "    \n",
        "    # return p\n",
        "    return p"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWGKJ5i-vhKV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for index, segment in instrument_samples_per_category['family_brass_note_60']['brass_acoustic_006-060-127'][feature_names].iterrows():\n",
        "  #print(segment)\n",
        "#print(means_per_category['family_string_note_24'])\n",
        "#print(instrument_samples_per_category['family_brass_note_60']['brass_acoustic_006-060-127'][feature_names].mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggvi9YDOlM8j",
        "colab_type": "code",
        "outputId": "dee64233-202c-44ab-fdc8-e69852f217ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# We initialize the lists were we save the accuracy percentages in both \n",
        "# test and training\n",
        "ac_percentage_per_repetition_train = []\n",
        "ac_percentage_per_repetition_test = []\n",
        "\n",
        "# Run the training/evaluation loop\n",
        "for i_repetition in range(cv_repetitions):\n",
        "\n",
        "  # We traverse each category\n",
        "  splited_instrument_sources_keys_per_category = {}\n",
        "  for family_note_category_key in family_note_category_keys:\n",
        "    # Random shuffle its intrument sources keys \n",
        "    np.random.shuffle(\n",
        "        instrument_sources_per_category_keys[family_note_category_key]\n",
        "        )\n",
        "    \n",
        "    # Split the instrument sources in k_cv partitions\n",
        "    splited_instrument_sources_keys_per_category[family_note_category_key] = \\\n",
        "      np.array(np.array_split(\n",
        "          instrument_sources_per_category_keys[family_note_category_key],\n",
        "          k_cv\n",
        "          ))\n",
        "    \n",
        "  # We initialize the lists were we save the accuracy percentages in both \n",
        "  # test and training per fold\n",
        "  ac_percentage_per_fold_train = []\n",
        "  ac_percentage_per_fold_test = []\n",
        "\n",
        "  # We traverse the partitions\n",
        "  for test_partition in range(k_cv):\n",
        "\n",
        "    # We initialize the dictionaries to store the means and variances of each\n",
        "    # category\n",
        "    means_per_category = {}\n",
        "    variances_per_category = {}\n",
        "\n",
        "    # Identifiers for test and train per category\n",
        "    test_keys_per_category = {}\n",
        "    train_keys_per_category = {}\n",
        "\n",
        "    # We traverse the categories\n",
        "    for family_note_category_key in family_note_category_keys:\n",
        "      \n",
        "      # We define the test and train keys\n",
        "      test_keys_per_category[family_note_category_key] = \\\n",
        "        splited_instrument_sources_keys_per_category[family_note_category_key][test_partition]\n",
        "\n",
        "      train_keys_per_category[family_note_category_key] = []\n",
        "      for temp_partition_i in range(len(splited_instrument_sources_keys_per_category[family_note_category_key])):\n",
        "        if (temp_partition_i == test_partition):\n",
        "          continue        \n",
        "        for element in splited_instrument_sources_keys_per_category[family_note_category_key][temp_partition_i]:\n",
        "          train_keys_per_category[family_note_category_key].append(element)\n",
        "\n",
        "      # We traverse the training samples to get the dataframe of it\n",
        "      current_category_train_df = pd.DataFrame()\n",
        "      for category_train_key in train_keys_per_category[family_note_category_key]:\n",
        "        current_category_train_df = current_category_train_df.append(instrument_samples_per_category[family_note_category_key][category_train_key][feature_names])\n",
        "      \n",
        "      # We traverse the test samples to get the dataframe of it\n",
        "      current_category_test_df = pd.DataFrame()\n",
        "      for category_test_key in test_keys_per_category[family_note_category_key]:\n",
        "        current_category_test_df = current_category_test_df.append(instrument_samples_per_category[family_note_category_key][category_test_key][feature_names])\n",
        "\n",
        "      variances_per_category[family_note_category_key] = current_category_train_df.var()\n",
        "      means_per_category[family_note_category_key] = current_category_train_df.mean()\n",
        "     \n",
        "    \n",
        "    # Once we obtained the means and variances we can now traverse the train and test splits to get the predictions\n",
        "    correct_predictions_in_partition_test = 0\n",
        "    correct_predictions_in_partition_train = 0\n",
        "    \n",
        "    # We traverse the train segments\n",
        "    for index, segment in current_category_train_df.iterrows():\n",
        "      # We initialize the max values we have seen\n",
        "      max_likely_cat = \"\"\n",
        "      max_prob_seen = -1.0\n",
        "\n",
        "      # We again traverse all categories to see which is the most likely\n",
        "      for prediction_famnote_label in family_note_category_keys:\n",
        "        current_prob = 1.0\n",
        "        \n",
        "        for feature_name in feature_names:\n",
        "          current_prob *= Gaussian_PDF(\n",
        "                segment[feature_name],\n",
        "                means_per_category[prediction_famnote_label][feature_name],\n",
        "                variances_per_category[prediction_famnote_label][feature_name]\n",
        "              )\n",
        "        \n",
        "        current_prob *= p_y_num\n",
        "        current_prob /= p_y_den\n",
        "\n",
        "        if (current_prob > max_prob_seen):\n",
        "          max_prob_seen = current_prob\n",
        "          max_likely_cat = prediction_famnote_label\n",
        "          \n",
        "      if (max_likely_cat == family_notes_df.loc[index]['NOTE_CLASS']):\n",
        "        correct_predictions_in_partition_train += 1\n",
        "        \n",
        "    # We traverse the test segments\n",
        "    for index, segment in current_category_test_df.iterrows():\n",
        "      # We initialize the max values we have seen\n",
        "      max_likely_cat = \"\"\n",
        "      max_prob_seen = -1.0\n",
        "\n",
        "      # We again traverse all categories to see which is the most likely\n",
        "      for prediction_famnote_label in family_note_category_keys:\n",
        "        current_prob = 1.0\n",
        "        \n",
        "        for feature_name in feature_names:\n",
        "          current_prob *= Gaussian_PDF(\n",
        "                segment[feature_name],\n",
        "                means_per_category[prediction_famnote_label][feature_name],\n",
        "                variances_per_category[prediction_famnote_label][feature_name]\n",
        "              )\n",
        "        \n",
        "        current_prob *= p_y_num\n",
        "        current_prob /= p_y_den\n",
        "\n",
        "        if (current_prob > max_prob_seen):\n",
        "          max_prob_seen = current_prob\n",
        "          max_likely_cat = prediction_famnote_label\n",
        "          \n",
        "      if (max_likely_cat == family_notes_df.loc[index]['NOTE_CLASS']):\n",
        "        correct_predictions_in_partition_test += 1\n",
        "\n",
        "    # We save per fold results\n",
        "    ac_percentage_per_fold_train.append(correct_predictions_in_partition_train * 100 / current_category_train_df.shape[0])\n",
        "    ac_percentage_per_fold_test.append(correct_predictions_in_partition_test * 100 / current_category_test_df.shape[0])\n",
        "    \n",
        "    # We print current result\n",
        "    print ('Repetition {0}/{1} - Partition {2}/{3} - Accuracy TRAIN {4}% - Accuracy TEST {5}%'.format( \n",
        "        (i_repetition + 1), \n",
        "        cv_repetitions, \n",
        "        (test_partition + 1), \n",
        "        k_cv,\n",
        "        ac_percentage_per_fold_train[-1],\n",
        "        ac_percentage_per_fold_test[-1]\n",
        "        )\n",
        "    )\n",
        "\n",
        "  # We save per repetition results\n",
        "  ac_percentage_per_repetition_train.append(np.array(ac_percentage_per_fold_train).mean())\n",
        "  ac_percentage_per_repetition_test.append(np.array(ac_percentage_per_fold_test).mean())"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Repetition 1/10 - Partition 1/7 - Accuracy TRAIN 94.79166666666667% - Accuracy TEST 90.625%\n",
            "Repetition 1/10 - Partition 2/7 - Accuracy TRAIN 91.66666666666667% - Accuracy TEST 81.25%\n",
            "Repetition 1/10 - Partition 3/7 - Accuracy TRAIN 93.22916666666667% - Accuracy TEST 84.375%\n",
            "Repetition 1/10 - Partition 4/7 - Accuracy TRAIN 94.27083333333333% - Accuracy TEST 87.5%\n",
            "Repetition 1/10 - Partition 5/7 - Accuracy TRAIN 93.22916666666667% - Accuracy TEST 96.875%\n",
            "Repetition 1/10 - Partition 6/7 - Accuracy TRAIN 93.75% - Accuracy TEST 96.875%\n",
            "Repetition 1/10 - Partition 7/7 - Accuracy TRAIN 94.27083333333333% - Accuracy TEST 87.5%\n",
            "Repetition 2/10 - Partition 1/7 - Accuracy TRAIN 95.3125% - Accuracy TEST 87.5%\n",
            "Repetition 2/10 - Partition 2/7 - Accuracy TRAIN 93.75% - Accuracy TEST 84.375%\n",
            "Repetition 2/10 - Partition 3/7 - Accuracy TRAIN 92.70833333333333% - Accuracy TEST 90.625%\n",
            "Repetition 2/10 - Partition 4/7 - Accuracy TRAIN 92.70833333333333% - Accuracy TEST 100.0%\n",
            "Repetition 2/10 - Partition 5/7 - Accuracy TRAIN 94.27083333333333% - Accuracy TEST 87.5%\n",
            "Repetition 2/10 - Partition 6/7 - Accuracy TRAIN 93.22916666666667% - Accuracy TEST 84.375%\n",
            "Repetition 2/10 - Partition 7/7 - Accuracy TRAIN 94.27083333333333% - Accuracy TEST 96.875%\n",
            "Repetition 3/10 - Partition 1/7 - Accuracy TRAIN 93.22916666666667% - Accuracy TEST 81.25%\n",
            "Repetition 3/10 - Partition 2/7 - Accuracy TRAIN 91.14583333333333% - Accuracy TEST 75.0%\n",
            "Repetition 3/10 - Partition 3/7 - Accuracy TRAIN 93.22916666666667% - Accuracy TEST 84.375%\n",
            "Repetition 3/10 - Partition 4/7 - Accuracy TRAIN 93.22916666666667% - Accuracy TEST 100.0%\n",
            "Repetition 3/10 - Partition 5/7 - Accuracy TRAIN 91.66666666666667% - Accuracy TEST 93.75%\n",
            "Repetition 3/10 - Partition 6/7 - Accuracy TRAIN 94.27083333333333% - Accuracy TEST 87.5%\n",
            "Repetition 3/10 - Partition 7/7 - Accuracy TRAIN 94.27083333333333% - Accuracy TEST 90.625%\n",
            "Repetition 4/10 - Partition 1/7 - Accuracy TRAIN 92.70833333333333% - Accuracy TEST 90.625%\n",
            "Repetition 4/10 - Partition 2/7 - Accuracy TRAIN 94.79166666666667% - Accuracy TEST 90.625%\n",
            "Repetition 4/10 - Partition 3/7 - Accuracy TRAIN 95.3125% - Accuracy TEST 87.5%\n",
            "Repetition 4/10 - Partition 4/7 - Accuracy TRAIN 92.70833333333333% - Accuracy TEST 96.875%\n",
            "Repetition 4/10 - Partition 5/7 - Accuracy TRAIN 93.75% - Accuracy TEST 87.5%\n",
            "Repetition 4/10 - Partition 6/7 - Accuracy TRAIN 94.27083333333333% - Accuracy TEST 87.5%\n",
            "Repetition 4/10 - Partition 7/7 - Accuracy TRAIN 92.1875% - Accuracy TEST 75.0%\n",
            "Repetition 5/10 - Partition 1/7 - Accuracy TRAIN 93.22916666666667% - Accuracy TEST 90.625%\n",
            "Repetition 5/10 - Partition 2/7 - Accuracy TRAIN 93.22916666666667% - Accuracy TEST 71.875%\n",
            "Repetition 5/10 - Partition 3/7 - Accuracy TRAIN 92.70833333333333% - Accuracy TEST 100.0%\n",
            "Repetition 5/10 - Partition 4/7 - Accuracy TRAIN 93.22916666666667% - Accuracy TEST 96.875%\n",
            "Repetition 5/10 - Partition 5/7 - Accuracy TRAIN 94.27083333333333% - Accuracy TEST 90.625%\n",
            "Repetition 5/10 - Partition 6/7 - Accuracy TRAIN 93.75% - Accuracy TEST 93.75%\n",
            "Repetition 5/10 - Partition 7/7 - Accuracy TRAIN 93.22916666666667% - Accuracy TEST 71.875%\n",
            "Repetition 6/10 - Partition 1/7 - Accuracy TRAIN 93.75% - Accuracy TEST 84.375%\n",
            "Repetition 6/10 - Partition 2/7 - Accuracy TRAIN 93.22916666666667% - Accuracy TEST 93.75%\n",
            "Repetition 6/10 - Partition 3/7 - Accuracy TRAIN 92.70833333333333% - Accuracy TEST 71.875%\n",
            "Repetition 6/10 - Partition 4/7 - Accuracy TRAIN 93.75% - Accuracy TEST 84.375%\n",
            "Repetition 6/10 - Partition 5/7 - Accuracy TRAIN 93.22916666666667% - Accuracy TEST 100.0%\n",
            "Repetition 6/10 - Partition 6/7 - Accuracy TRAIN 93.75% - Accuracy TEST 96.875%\n",
            "Repetition 6/10 - Partition 7/7 - Accuracy TRAIN 94.27083333333333% - Accuracy TEST 87.5%\n",
            "Repetition 7/10 - Partition 1/7 - Accuracy TRAIN 94.27083333333333% - Accuracy TEST 81.25%\n",
            "Repetition 7/10 - Partition 2/7 - Accuracy TRAIN 92.70833333333333% - Accuracy TEST 100.0%\n",
            "Repetition 7/10 - Partition 3/7 - Accuracy TRAIN 93.75% - Accuracy TEST 96.875%\n",
            "Repetition 7/10 - Partition 4/7 - Accuracy TRAIN 94.79166666666667% - Accuracy TEST 87.5%\n",
            "Repetition 7/10 - Partition 5/7 - Accuracy TRAIN 94.27083333333333% - Accuracy TEST 84.375%\n",
            "Repetition 7/10 - Partition 6/7 - Accuracy TRAIN 94.27083333333333% - Accuracy TEST 93.75%\n",
            "Repetition 7/10 - Partition 7/7 - Accuracy TRAIN 94.27083333333333% - Accuracy TEST 71.875%\n",
            "Repetition 8/10 - Partition 1/7 - Accuracy TRAIN 92.70833333333333% - Accuracy TEST 96.875%\n",
            "Repetition 8/10 - Partition 2/7 - Accuracy TRAIN 94.79166666666667% - Accuracy TEST 90.625%\n",
            "Repetition 8/10 - Partition 3/7 - Accuracy TRAIN 94.27083333333333% - Accuracy TEST 78.125%\n",
            "Repetition 8/10 - Partition 4/7 - Accuracy TRAIN 93.22916666666667% - Accuracy TEST 81.25%\n",
            "Repetition 8/10 - Partition 5/7 - Accuracy TRAIN 94.27083333333333% - Accuracy TEST 93.75%\n",
            "Repetition 8/10 - Partition 6/7 - Accuracy TRAIN 92.70833333333333% - Accuracy TEST 93.75%\n",
            "Repetition 8/10 - Partition 7/7 - Accuracy TRAIN 93.75% - Accuracy TEST 93.75%\n",
            "Repetition 9/10 - Partition 1/7 - Accuracy TRAIN 93.75% - Accuracy TEST 81.25%\n",
            "Repetition 9/10 - Partition 2/7 - Accuracy TRAIN 93.22916666666667% - Accuracy TEST 96.875%\n",
            "Repetition 9/10 - Partition 3/7 - Accuracy TRAIN 93.75% - Accuracy TEST 96.875%\n",
            "Repetition 9/10 - Partition 4/7 - Accuracy TRAIN 93.75% - Accuracy TEST 84.375%\n",
            "Repetition 9/10 - Partition 5/7 - Accuracy TRAIN 94.79166666666667% - Accuracy TEST 81.25%\n",
            "Repetition 9/10 - Partition 6/7 - Accuracy TRAIN 93.22916666666667% - Accuracy TEST 81.25%\n",
            "Repetition 9/10 - Partition 7/7 - Accuracy TRAIN 93.75% - Accuracy TEST 96.875%\n",
            "Repetition 10/10 - Partition 1/7 - Accuracy TRAIN 93.75% - Accuracy TEST 96.875%\n",
            "Repetition 10/10 - Partition 2/7 - Accuracy TRAIN 93.75% - Accuracy TEST 84.375%\n",
            "Repetition 10/10 - Partition 3/7 - Accuracy TRAIN 93.22916666666667% - Accuracy TEST 96.875%\n",
            "Repetition 10/10 - Partition 4/7 - Accuracy TRAIN 94.79166666666667% - Accuracy TEST 84.375%\n",
            "Repetition 10/10 - Partition 5/7 - Accuracy TRAIN 93.75% - Accuracy TEST 93.75%\n",
            "Repetition 10/10 - Partition 6/7 - Accuracy TRAIN 93.75% - Accuracy TEST 84.375%\n",
            "Repetition 10/10 - Partition 7/7 - Accuracy TRAIN 94.79166666666667% - Accuracy TEST 81.25%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONGZU8AnOYeB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "babab477-3f90-485a-ae88-2216bfaa0434"
      },
      "source": [
        "# We Report the average percentage per repetition in train\n",
        "ac_percentage_per_repetition_train"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[93.60119047619048,\n",
              " 93.75,\n",
              " 93.0059523809524,\n",
              " 93.67559523809523,\n",
              " 93.37797619047619,\n",
              " 93.52678571428574,\n",
              " 94.04761904761905,\n",
              " 93.67559523809523,\n",
              " 93.75,\n",
              " 93.97321428571429]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OV-abE-mmJzr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "815185c9-d967-42d1-d417-4daf2b40f27a"
      },
      "source": [
        "# We report the average percentage per repetition in test\n",
        "ac_percentage_per_repetition_test"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[89.28571428571429,\n",
              " 90.17857142857143,\n",
              " 87.5,\n",
              " 87.94642857142857,\n",
              " 87.94642857142857,\n",
              " 88.39285714285714,\n",
              " 87.94642857142857,\n",
              " 89.73214285714286,\n",
              " 88.39285714285714,\n",
              " 88.83928571428571]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OR3VLGMxmyja",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bc392795-0fce-44e0-b942-cda42002c0b3"
      },
      "source": [
        "# We report the average of all repetitions in train\n",
        "np.array(ac_percentage_per_repetition_train).mean()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "93.63839285714286"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoQvD3uXm-MK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "36016098-42b4-4383-f413-19a1df229563"
      },
      "source": [
        "# We report the average of all repetitions in test\n",
        "np.array(ac_percentage_per_repetition_test).mean()"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "88.61607142857142"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfHVctXtnLv6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We Export the last models means and variances to further inference tests\n",
        "means_last_model_df = pd.DataFrame(means_per_category).T\n",
        "means_last_model_df.to_csv('means_last_model.csv', index=True)\n",
        "\n",
        "variances_last_model_df = pd.DataFrame(variances_per_category).T\n",
        "variances_last_model_df.to_csv('variances_last_model.csv', index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}