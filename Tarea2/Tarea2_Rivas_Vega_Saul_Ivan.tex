\documentclass[12pt]{article}
\usepackage{geometry}
\geometry{
	left=20mm,
	top=20mm,
}
\usepackage[utf8]{inputenc}
\usepackage[shortlabels]{enumitem}
\usepackage{array}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\usepackage[spanish,es-nodecimaldot]{babel}
 \usepackage{url}
\usepackage[spanish, fixlanguage]{babelbib}
\bibliographystyle{IEEEtran}
\usepackage{graphicx}
\graphicspath{ {./images/} }
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{subcaption}
\usepackage[linesnumbered]{algorithm2e}
\newcommand\mycommfont[1]{\footnotesize\ttfamily\textcolor{blue}{#1}}
\SetCommentSty{mycommfont}
\usepackage{tikz}
\usetikzlibrary{positioning, fit}
\usetikzlibrary{babel}
\usepackage{titlesec}
\titlespacing*{\section}
{0pt}{5.5ex plus 1ex minus .2ex}{.3ex plus .1ex}
\titlespacing*{\subsection}
{0pt}{5.5ex plus 1ex minus .2ex}{2.3ex plus .1ex}
\title{Tarea 2: Clasificador bayesiano ingenuo}

\author{
	Saul Ivan Rivas Vega \\
	\\
	Aprendizaje Automatizado\\
}

\date{\today}

\begin{document}
	\maketitle
	\pagebreak
	\section{Géneros}
	  \paragraph{} Un programa de salud gubernamental desea clasificar los registros de las personas en géneros femenino (F) o masculino (M) a partir de los atributos nombre, estatura y peso. Se cuentan con los
	  siguientes registros:\\
	  \begin{figure}[h!]
	  	\centering
	  	\includegraphics[width=.6\linewidth]{excercise1}
	  	\label{fig1}
	  \end{figure}
  \paragraph{} Entrena un clasificador bayesiano ingenuo usando estimación por máxima verosimilitud y otro usando estimación por máximo a posteriori. Reporta los parámetros que obtuviste en ambos casos y usa los clasificadores entrenados para predecir la clase de los siguientes vectores: x1 = (Rene, 1.68, 65), x2 = (Guadalupe, 1.75, 80), x3 = (Denis, 1.80, 79), x4 = (Alex, 190, 85) y x5 = (Cris, 165, 70).
  Describe de forma detallada el procedimiento que seguiste tanto en el entrenamiento como en la predicción y discute los resultados obtenidos.
  Para el entrenamiento del clasificador por máximo a posteriori considera los siguientes valores
  para las distribuciones correspondientes:
	  \begin{figure}[h!]
	  	\centering
	  	\includegraphics[width=.6\linewidth]{ex1_002}
	  	\label{fig2}
	  \end{figure}
 \subsection{Estimador por máxima verosimilitud}
 \paragraph{} Los atributos son: \textbf{nombre}, \textbf{estatura} y \textbf{peso}, y la clase es \textbf{género}.\\
 \subsubsection{Atributo \textit{Nombre}}
 \paragraph{} Para el \textbf{nombre} podemos asumir una distribución categórica:
  \begin{equation}
  \begin{split}
  X_{nombre}^{(i)}\sim Cat(X_{nombre}^{(i)};q)\\
  \end{split}
  \end{equation}
  Donde las categorías son los nombres y los podemos enumerar:
  \begin{enumerate}
  	\item Denis
  	\item Guadalupe
  	\item Alex
  	\item Cris
  	\item Juan
  	\item Rene
  \end{enumerate}
  Y así con los nombres de 1 a 6 podemos definir a $Cat(X_{nombre}^{(i)};q)$ como:\\
  \begin{equation}
  \begin{split}
  Cat(X_{nombre}^{(i)};q) = \prod_{k=1}^{6}q_{k}^{[x_{nombre}^{(i)}=k ]}\\
  \end{split}
  \end{equation}
  Donde podemos estimar a $q_k$ usando el estimador de máxima verosimilitud como:
  \begin{equation}
  \begin{split}
  \hat{q}_k =& \frac{c_k}{n} \\ 
  \text{Donde $c_k$:}&\\
  c_k =& \sum_{i = 1}^{n}{[x^{(i)}_{nombre}=k]}
  \end{split}
  \end{equation}
  Así podemos estimar el parámetro para la primer categoría:\\
  \begin{equation}
  \begin{split}
  	\text{Para la clase \textbf{Femenino}}:\\
  	c_{1F} &= \sum_{i = 1}^{13}{[x^{(i)}_{nombre}=1 \text{ y $x^{(i)}$ es de la clase Femenino}]}\\
  	&= 0 + 0 + 0 + 0 + 0 + 0 + 0 + 0 + 1 + 0 + 0 + 0 + 0 + 0\\
  	&= 1\\
  \hat{q}_{(1|F)} =& \frac{1}{6} \\ 
  \text{Para la clase \textbf{Masculino}}:\\
  c_{1M} &= \sum_{i = 1}^{13}{[x^{(i)}_{nombre}=1 \text{ y $x^{(i)}$ es de la clase Masculino}]}\\
  &= 1 + 0 + 0 + 0 + 0 + 0 + 0 + 0 + 0 + 0 + 0 + 0 + 0 + 0\\
  &= 1\\
  \hat{q}_{(1|M)} =& \frac{1}{7} \\
  \end{split}
  \end{equation}
  Y de la misma forma para las categorías restantes:
  \begin{equation}
  \begin{split}
  c_{2F} = 2, \; \hat{q}_{(2|F)} = \frac{2}{6}, \; c_{2M} = 1, \; \hat{q}_{(2|M)} = \frac{1}{7} \; \; \; \; \; \; \; \; \; \; \; \; &  c_{3F} = 1, \; \hat{q}_{(3|F)} = \frac{1}{6}, \; c_{3M} = 2, \; \hat{q}_{(3|M)} = \frac{2}{7}\\
  c_{4F} = 1, \; \hat{q}_{(4|F)} = \frac{1}{6}, \; c_{4M} = 1, \; \hat{q}_{(4|M)} = \frac{1}{7} \; \; \; \; \; \; \; \; \; \; \; \; &  c_{5F} = 0, \; \hat{q}_{(5|F)} = \frac{0}{6} = 0, \; c_{5M} = 2, \; \hat{q}_{(5|M)} = \frac{2}{7}\\ 
  c_{6F} = 1, \; \hat{q}_{(6|F)} = \frac{1}{6}, \;c_{6M} = 0, \; \hat{q}_{(6|M)} = \frac{0}{7} = 0\\
  \end{split}
  \end{equation}
  \subsubsection{Atributo Estatura}
  \paragraph{}Para la \textbf{estatura} podemos asumir una distribución normal:
  \begin{equation}
  \begin{split}
  X_{estatura}^{(i)}\sim \mathcal{N}(X_{estatura}^{(i)};\mu;\sigma^2)\\
  \end{split}
  \end{equation}
  Donde $\mathcal{N}(X_{estatura}^{(i)};\mu;\sigma^2)$ se define como:\\
  \begin{equation}
  \begin{split}
  \mathcal{N}(X_{estatura}^{(i)};\mu;\sigma^2) =& \frac{1}{\sqrt{2\pi\sigma^2}}e^{\frac{-(x^{(i)} - \mu)^2}{2\sigma^2}}\\
  \end{split}
  \end{equation}
  Donde podemos estimar a $\mu$ y a $\sigma$ usando el estimador de máxima verosimilitud como:
  \paragraph{} Para la clase \textbf{Femenino}:
  \begin{equation}
  \begin{split}
  \hat{\mu}_{F}&=\frac{1}{n}\sum_{i=1}^{n}{x_{estatura}^{(i)}}\\
  &=\frac{1}{6}(1.50 + 1.52 + 1.62 + 1.67 + 1.65 + 1.75)\\
   &=\frac{1}{6}(9.71)\\
   &= 1.618\bar{3}\\
  \end{split}
  \end{equation}
  \begin{equation}
  \begin{split}
  \hat{\sigma}^2_F&=\frac{1}{n}\sum_{i=1}^{n}{(x_{estatura}^{(i)} - \hat{\mu})^2}\\
  &=\frac{1}{6}[(1.50-1.618\bar{3})^2 + (1.52-1.618\bar{3})^2  + \dots + (1.75-1.618\bar{3})^2)]\\
  &=\frac{1}{6}[0.014003 + 0.009669 + 0.00166667 + \dots + 0.13166667]\\
  &=\frac{1}{6}[0.13036923076923082]\\
  &= 0.021728205128205138\\
  \end{split}
  \end{equation}
  \subsubsection{Atributo Peso}
  \paragraph{}Para el \textbf{peso} podemos asumir una distribución normal:
  \begin{equation}
  \begin{split}
  X_{peso}^{(i)}\sim \mathcal{N}(X_{peso}^{(i)};\mu;\sigma^2)\\
  \end{split}
  \end{equation}
  Donde $\mathcal{N}(X_{peso}^{(i)};\mu;\sigma^2)$ se define como:\\
  \begin{equation}
  \begin{split}
  \mathcal{N}(X_{peso}^{(i)};\mu;\sigma^2) =& \frac{1}{\sqrt{2\pi\sigma^2}}e^{\frac{-(x^{(i)} - \mu)^2}{2\sigma^2}}\\
  \end{split}
  \end{equation}
  Donde podemos estimar a $\mu$ y a $\sigma$ usando el estimador de máxima verosimilitud como:
  \begin{equation}
  \begin{split}
  \hat{\mu}&=\frac{1}{n}\sum_{i=1}^{n}{x_{peso}^{(i)}}\\
  &=\frac{1}{13}(75.3 + 81.6 + 86.1 + 77.1 + 78.2 + 74.8 + 74.3 + 50.5 + 45.3 + 61.2 + 68.0 + 58.9 + 68.0)\\
  &=\frac{1}{13}(899.3)\\
  &= 69.17692307692307\\
  \end{split}
  \end{equation}
  \begin{equation}
  \begin{split}
  \hat{\sigma}^2&=\frac{1}{n}\sum_{i=1}^{n}{(x_{peso}^{(i)} - \hat{\mu})^2}\\
  &=\frac{1}{13}[(75.3-69.17692)^2 + (81.6-69.17692)^2  + \dots + (68.0-69.17692)^2)]\\
  &=\frac{1}{13}[37.49207 + 154.33284 + 286.39053 + \dots + 1.38514]\\
  &=\frac{1}{13}[1771.2230769230764]\\
  &= 136.2479289940828\\
  \end{split}
  \end{equation}
  \subsubsection{Género}
  
 \section{Spam}
	 
\end{document}  